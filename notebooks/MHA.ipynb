{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7653c8-eb4e-4cc5-85ac-fbfa34147ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ce0fb8-0816-44db-9bca-7213c415de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470a20d3-5933-47cb-819d-671d6a4350ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1] # second input element\n",
    "d_in = inputs.shape[1] # the input embedding size, d=3\n",
    "d_out = 2 # the output embedding size, d=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fecfc18c-d440-4853-9217-4ea5565fb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50662b8-3087-469c-85b5-999f54bfa10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c15068e-f4ad-4bb0-b22a-23d2a3ee73df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23e76fd-b6e3-420a-ac36-77f66092435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_v1(inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c183b4c-9145-4bff-85a5-c7dd082fc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out)\n",
    "        self.W_key   = nn.Linear(d_in, d_out)\n",
    "        self.W_value = nn.Linear(d_in, d_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_key(x)\n",
    "        values = self.W_query(x)\n",
    "        \n",
    "        attn_scores = queries @ keys.T # omega\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5187a74-5fe7-4fc3-b4ee-8a7e209ff86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6648, -0.4255],\n",
      "        [-0.6640, -0.4314],\n",
      "        [-0.6640, -0.4310],\n",
      "        [-0.6632, -0.4309],\n",
      "        [-0.6642, -0.4230],\n",
      "        [-0.6629, -0.4346]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be0c468-4f23-4376-8fc7-fe37512853ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(torch.ones(4, 4), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16bcba9-bbc1-42d5-9fff-7ec4081b9ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "050c3656-2e36-481e-910b-f9d45bab14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336ba9c2-5e39-45f4-8a27-a67d4a1a18e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c5bc1f3-b1fb-4d3b-b049-14481be9a564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92260121-2cbb-4096-858d-db7b13ca6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "b, num_tokens, d_in = batch.shape # New batch dimension b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98751e17-f064-4587-a196-a5bcb1b6c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 32\n",
    "W_query = nn.Linear(d_in, 32)\n",
    "W_key   = nn.Linear(d_in, 32)\n",
    "W_value = nn.Linear(d_in, 32)\n",
    "dropout = nn.Dropout(0.25) # New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22d82afb-6d78-4062-bd73-dc75a56c5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch\n",
    "keys = W_key(x)\n",
    "queries = W_query(x)\n",
    "values = W_value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03956fba-f8a4-4306-89ed-ed373d62e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb268f4-8baa-4514-82a7-d6733c41c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46ae67b1-e8e7-47f7-a85a-b40faa94c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 1.,  ..., 1., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0362e0d-ba0f-4291-98b2-e2f5d3d91c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e4c42d4-dd68-4ec3-b3a2-bd0814479c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.bool()[:num_tokens,:num_tokens].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "584aa263-10f8-46a5-b8b7-1b40b2c26191",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = queries@keys.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da8a0b41-6838-474e-b0e8-a15e3a9a1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb755cea-5a6f-4cd4-ba84-e096c977211a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfecb84d-c97a-4efa-9708-568538753df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.5112, 0.4888,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.3438, 0.3276, 0.3287,   -inf,   -inf,   -inf],\n",
       "         [0.2532, 0.2440, 0.2445, 0.2583,   -inf,   -inf],\n",
       "         [0.2095, 0.1888, 0.1892, 0.2048, 0.2076,   -inf],\n",
       "         [0.1627, 0.1621, 0.1624, 0.1713, 0.1744, 0.1670]],\n",
       "\n",
       "        [[1.0000,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.5112, 0.4888,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.3438, 0.3276, 0.3287,   -inf,   -inf,   -inf],\n",
       "         [0.2532, 0.2440, 0.2445, 0.2583,   -inf,   -inf],\n",
       "         [0.2095, 0.1888, 0.1892, 0.2048, 0.2076,   -inf],\n",
       "         [0.1627, 0.1621, 0.1624, 0.1713, 0.1744, 0.1670]]],\n",
       "       grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores.masked_fill_(\n",
    "    mask.bool()[:num_tokens,:num_tokens],\n",
    "    -torch.inf    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb65a372-ff48-400b-a7ea-f017bee1cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = torch.softmax(attn_scores/keys.shape[-1]**0.5, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ada6b503-d436-4fe8-a38c-c48b25478e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5112, 0.4888, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3438, 0.3276, 0.3287, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2532, 0.2440, 0.2445, 0.2583, 0.0000, 0.0000],\n",
       "         [0.2095, 0.1888, 0.1892, 0.2048, 0.2076, 0.0000],\n",
       "         [0.1627, 0.1621, 0.1624, 0.1713, 0.1744, 0.1670]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5112, 0.4888, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3438, 0.3276, 0.3287, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2532, 0.2440, 0.2445, 0.2583, 0.0000, 0.0000],\n",
       "         [0.2095, 0.1888, 0.1892, 0.2048, 0.2076, 0.0000],\n",
       "         [0.1627, 0.1621, 0.1624, 0.1713, 0.1744, 0.1670]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97d97d31-4ad7-484d-8191-608ea90d935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "                 dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) # New\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1)) # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2) # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)  # `:num_tokens` to account for cases where the number of tokens in the batch is smaller than the supported context_size\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights) # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af448e25-26c5-4fda-a2de-e914085bcf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f202062d-93f9-4f19-a141-8b9d73d17661",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_att = CausalAttention(d_in = 3, d_out = 32, context_length = 6, dropout = 0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b9dd20b-33f7-4a9b-8d77-f03269e48735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalAttention(\n",
       "  (W_query): Linear(in_features=3, out_features=32, bias=False)\n",
       "  (W_key): Linear(in_features=3, out_features=32, bias=False)\n",
       "  (W_value): Linear(in_features=3, out_features=32, bias=False)\n",
       "  (dropout): Dropout(p=0.24, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5bfef7b-021d-42fc-83bb-a08a4f524921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 32])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_att(batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "35d3967a-f299-44bb-a5b2-a9cfb1a78e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3326,  0.5659, -0.3132,  0.0752,  0.4566,  0.2729, -0.0322,\n",
      "          -0.4610,  0.2847, -0.3886, -0.1471,  0.4106,  0.2869,  0.2964,\n",
      "          -0.1885,  0.5982, -0.6053,  0.6575,  0.3087, -0.4569,  0.2649,\n",
      "           0.3223,  0.1336, -0.2467],\n",
      "         [ 0.3456,  0.5650, -0.2237,  0.0313,  0.5977,  0.3053, -0.2642,\n",
      "          -0.3017,  0.4047, -0.1700, -0.2532,  0.3527,  0.3626,  0.2247,\n",
      "          -0.3241,  0.6507, -0.5515,  0.6564,  0.2733, -0.6272,  0.3056,\n",
      "           0.2533,  0.0792, -0.2004],\n",
      "         [ 0.3440,  0.5604, -0.2000,  0.0178,  0.6413,  0.3138, -0.3371,\n",
      "          -0.2502,  0.4369, -0.1055, -0.2813,  0.3304,  0.3880,  0.2032,\n",
      "          -0.3675,  0.6669, -0.5324,  0.6538,  0.2588, -0.6824,  0.3120,\n",
      "           0.2272,  0.0577, -0.1865],\n",
      "         [ 0.3103,  0.4941, -0.1606,  0.0089,  0.5729,  0.2785, -0.3210,\n",
      "          -0.2028,  0.4068, -0.0654, -0.2649,  0.2920,  0.3533,  0.1571,\n",
      "          -0.3522,  0.5905, -0.4536,  0.5714,  0.2231, -0.6161,  0.2913,\n",
      "           0.1874,  0.0447, -0.1464],\n",
      "         [ 0.2430,  0.4287, -0.1643,  0.0071,  0.5566,  0.2514, -0.3377,\n",
      "          -0.1566,  0.3424, -0.0584, -0.2268,  0.2288,  0.3361,  0.1866,\n",
      "          -0.3058,  0.5567, -0.4282,  0.5282,  0.1806, -0.5986,  0.2039,\n",
      "           0.1560,  0.0139, -0.1672],\n",
      "         [ 0.2648,  0.4316, -0.1375,  0.0023,  0.5363,  0.2508, -0.3262,\n",
      "          -0.1548,  0.3678, -0.0315, -0.2445,  0.2433,  0.3284,  0.1422,\n",
      "          -0.3274,  0.5341, -0.3983,  0.5071,  0.1892, -0.5765,  0.2532,\n",
      "           0.1535,  0.0261, -0.1310]],\n",
      "\n",
      "        [[ 0.3326,  0.5659, -0.3132,  0.0752,  0.4566,  0.2729, -0.0322,\n",
      "          -0.4610,  0.2847, -0.3886, -0.1471,  0.4106,  0.2869,  0.2964,\n",
      "          -0.1885,  0.5982, -0.6053,  0.6575,  0.3087, -0.4569,  0.2649,\n",
      "           0.3223,  0.1336, -0.2467],\n",
      "         [ 0.3456,  0.5650, -0.2237,  0.0313,  0.5977,  0.3053, -0.2642,\n",
      "          -0.3017,  0.4047, -0.1700, -0.2532,  0.3527,  0.3626,  0.2247,\n",
      "          -0.3241,  0.6507, -0.5515,  0.6564,  0.2733, -0.6272,  0.3056,\n",
      "           0.2533,  0.0792, -0.2004],\n",
      "         [ 0.3440,  0.5604, -0.2000,  0.0178,  0.6413,  0.3138, -0.3371,\n",
      "          -0.2502,  0.4369, -0.1055, -0.2813,  0.3304,  0.3880,  0.2032,\n",
      "          -0.3675,  0.6669, -0.5324,  0.6538,  0.2588, -0.6824,  0.3120,\n",
      "           0.2272,  0.0577, -0.1865],\n",
      "         [ 0.3103,  0.4941, -0.1606,  0.0089,  0.5729,  0.2785, -0.3210,\n",
      "          -0.2028,  0.4068, -0.0654, -0.2649,  0.2920,  0.3533,  0.1571,\n",
      "          -0.3522,  0.5905, -0.4536,  0.5714,  0.2231, -0.6161,  0.2913,\n",
      "           0.1874,  0.0447, -0.1464],\n",
      "         [ 0.2430,  0.4287, -0.1643,  0.0071,  0.5566,  0.2514, -0.3377,\n",
      "          -0.1566,  0.3424, -0.0584, -0.2268,  0.2288,  0.3361,  0.1866,\n",
      "          -0.3058,  0.5567, -0.4282,  0.5282,  0.1806, -0.5986,  0.2039,\n",
      "           0.1560,  0.0139, -0.1672],\n",
      "         [ 0.2648,  0.4316, -0.1375,  0.0023,  0.5363,  0.2508, -0.3262,\n",
      "          -0.1548,  0.3678, -0.0315, -0.2445,  0.2433,  0.3284,  0.1422,\n",
      "          -0.3274,  0.5341, -0.3983,  0.5071,  0.1892, -0.5765,  0.2532,\n",
      "           0.1535,  0.0261, -0.1310]]], grad_fn=<CatBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 24])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) \n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "context_length = batch.shape[1] # This is the number of tokens\n",
    "d_in, d_out = 3, 3\n",
    "mha = MultiHeadAttentionWrapper(\n",
    "    d_in, d_out, context_length, 0.0, num_heads=8\n",
    ")\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a9d9e6a-8b82-449a-835f-cffb2324b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e857a914-e37b-4cd1-9c67-b649e0f0c4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4060, -0.0417, -0.7316,  0.1562, -0.0687,  0.0826,  0.5215,\n",
      "           0.2318,  0.3004,  0.2771, -0.1343,  0.0142, -0.4592,  0.4092,\n",
      "           0.0128, -0.6038],\n",
      "         [ 0.4464,  0.1098, -0.8581,  0.2798, -0.0649,  0.0994,  0.5518,\n",
      "           0.1860,  0.2879,  0.2076, -0.0533, -0.0197, -0.5703,  0.4576,\n",
      "          -0.0516, -0.4887],\n",
      "         [ 0.4561,  0.1537, -0.8914,  0.3179, -0.0628,  0.1025,  0.5589,\n",
      "           0.1680,  0.2832,  0.1851, -0.0255, -0.0322, -0.6010,  0.4690,\n",
      "          -0.0720, -0.4524],\n",
      "         [ 0.4308,  0.1482, -0.8345,  0.3191, -0.0717,  0.0896,  0.5268,\n",
      "           0.1333,  0.2724,  0.1739,  0.0122, -0.0243, -0.5601,  0.4471,\n",
      "          -0.0932, -0.3953],\n",
      "         [ 0.4071,  0.0852, -0.7406,  0.3178, -0.0619,  0.0903,  0.4936,\n",
      "           0.0839,  0.2705,  0.1813,  0.0401, -0.0211, -0.5070,  0.3798,\n",
      "          -0.1069, -0.3775],\n",
      "         [ 0.4096,  0.1227, -0.7687,  0.3228, -0.0725,  0.0852,  0.4970,\n",
      "           0.0937,  0.2659,  0.1676,  0.0434, -0.0190, -0.5208,  0.4098,\n",
      "          -0.1134, -0.3543]],\n",
      "\n",
      "        [[ 0.4060, -0.0417, -0.7316,  0.1562, -0.0687,  0.0826,  0.5215,\n",
      "           0.2318,  0.3004,  0.2771, -0.1343,  0.0142, -0.4592,  0.4092,\n",
      "           0.0128, -0.6038],\n",
      "         [ 0.4464,  0.1098, -0.8581,  0.2798, -0.0649,  0.0994,  0.5518,\n",
      "           0.1860,  0.2879,  0.2076, -0.0533, -0.0197, -0.5703,  0.4576,\n",
      "          -0.0516, -0.4887],\n",
      "         [ 0.4561,  0.1537, -0.8914,  0.3179, -0.0628,  0.1025,  0.5589,\n",
      "           0.1680,  0.2832,  0.1851, -0.0255, -0.0322, -0.6010,  0.4690,\n",
      "          -0.0720, -0.4524],\n",
      "         [ 0.4308,  0.1482, -0.8345,  0.3191, -0.0717,  0.0896,  0.5268,\n",
      "           0.1333,  0.2724,  0.1739,  0.0122, -0.0243, -0.5601,  0.4471,\n",
      "          -0.0932, -0.3953],\n",
      "         [ 0.4071,  0.0852, -0.7406,  0.3178, -0.0619,  0.0903,  0.4936,\n",
      "           0.0839,  0.2705,  0.1813,  0.0401, -0.0211, -0.5070,  0.3798,\n",
      "          -0.1069, -0.3775],\n",
      "         [ 0.4096,  0.1227, -0.7687,  0.3228, -0.0725,  0.0852,  0.4970,\n",
      "           0.0937,  0.2659,  0.1676,  0.0434, -0.0190, -0.5208,  0.4098,\n",
      "          -0.1134, -0.3543]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 16])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        # print('CONTEXT VEC: ', context_vec.shape)\n",
    "        # print('CONTEXT VEC: ', context_vec.contiguous().shape)\n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 16\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=8)\n",
    "\n",
    "context_vecs = mha(batch)\n",
    "\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0998c8d9-08ba-460d-abb9-62982cb94918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ecdf3-5b59-4621-abfb-a4e23dab06a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
